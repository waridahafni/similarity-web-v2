{
  "original_text": "RINGKASAN JUDUL YANG DIAJUKAN\n*Semua kolom di bawah ini diisi oleh mahasiswa yang sudah mendapat judul\nJudul / Topik\nIDENTIFIKASI PERNYATAAN MISOGINI BERDASARKAN KOMENTAR MEDIA SOSIAL\nSkripsi\nMENGGUNAKAN BIDIRECTIONAL LONG SHORT-TERM DAN INDOBERT EMBEDDING\nLatar Belakang, Latar Belakang\nPenelitian\nDi Indonesia, masih sering ditemukan masyarakat yang menganut paham patriarki. Hal ini\nTerdahulu, dan\nPerbedaan\nmembuat misogini masih terus berkembang secara luas seiring dengan perkembangan ideologi\nPenelitian\ntersebut. Misogini sendiri memiliki arti kebencian terhadap perempuan dan pemahaman ini telah\nmelahirkan seorang misoginis. Seorang misoginis memiliki sikap yang memandang bahwa\nperempuan merupakan pihak yang layak untuk disudutkan, ditindas, dan dieksploitasi, serta\nmendapat kebencian. Selain hal ini, terdapat juga kebiasaan yang meremehkan dan\nmenomorduakan perempuan, menghina dan mendiskriminasikan perempuan, serta menganggap\nbahwa perempuan layak dilecehkan dan diberi kekerasan (Lubis, 2021) (Maharani, 2022).\nAdapun contoh pernyataan misogini dapat dilihat pada gambar di bawah ini.\nTentunya, perilaku ini sudah termasuk kedalam tindakan kekerasan terhadap perempuan dan\ntelah melanggar prinsip HAM terkait kesetaraan dan nondiskriminasi. Meskipun demikian,\nperilaku ini masih tersebar luas dan bahkan dapat ditemukan di media sosial.\nPenggunaan media sosial yang identik dilakukan secara anonim mengakibatkan sering kali\nditemukan pernyataan atau unggahan yang tidak berkenan terhadap sesama masyarakat terutama\nterhadap perempuan. Hal tersebut diperkuat pernyataannya berdasarkan laporan oleh National\nDemocratic Institute (National Democratic Institute, 2019), dimana dikatakan bahwa\nperempuan-perempuan di Kolombia, Kenya, dan Indonesia menjadi yang paling umum\nmengalami kekerasan secara online berupa bahasa yang menghina. Dan dalam Catatan Tahunan\n(CATAHU) 2023 (Fuad et al., 2023), Komisi Nasional Anti Kekerasan terhadap Perempuan\n(Komnas Perempuan) mendapatkan pengaduan kasus Kekerasan Siber Berbasis Gender (KSBG)\nsebanyak 1697 kasus yang dimana 869 kasus diantaranya terjadi di ranah publik. Di antara\nkasus-kasus tersebut, sebanyak 383 pelaku merupakan teman media sosial korban dan 304\npelaku merupakan orang yang tidak dikenal oleh korban. Selain Komnas Perempuan, terdapat\njuga catatan pengaduan dari Lembaga Layanan yang menyatakan sebanyak 148 kasus KSBG\ndiantara semua kasus yang diadukan. Banyaknya kasus yang terjadi ini dapat dan telah\nmenimbulkan rasa tidak aman terhadap perempuan dalam menggunakan teknologi seperti\nhalnya media sosial. Bahkan, beberapa perempuan diantaranya menghentikan sementara\naktivitas mereka di media sosial dan terdapat juga yang berhenti secara permanen menggunakan\nmedia sosial (National Democratic Institute, 2019).\nHal terkait kekerasan melalui jejaring sosial ini tentunya perlu diamati dan dicermati lebih\nlanjut karena telah merugikan perempuan, terutama terkait misogini yang menjadi salah satu\nbentuknya. Akan tetapi, untuk membuktikan suatu pernyataan merupakan misogini atau bukan,\ndiperlukan ketelitian dan pemahaman terhadap setiap konteks kalimat yang ada pada komentar.\nHal tersebut tentunya akan menghabiskan waktu yang cukup lama untuk membuktikan\npernyataannya satu per satu. Sehingga diperlukan suatu pendekatan yang dapat mempermudah\nproses tersebut.\nPendekatan yang dapat dilakukan ialah dengan melakukan identifikasi pernyataan misogini\nmenggunakan metode pembelajaran mesin. Sebelumnya telah dilakukan beberapa penelitian\nyang serupa, diantaranya penelitian yang berjudul “Identifikasi Pernyataan Misogini Berbahasa\nIndonesia Berdasarkan Komentar Youtube Menggunakan GloVe Embedding dan Random\nForest Classifier” (Damanik, 2021). Penelitian tersebut berupa skripsi yang melakukan\nidentifikasi pernyataan misogini yang diinput dalam bentuk dokumen menggunakan algoritma\nRandom Forest (RF) dan GloVe Embedding dengan hasil akurasi 92,5%. Penelitian lainnya\nberjudul “Misogyny Speech Detection Using Long Short-Term Memory and BERT Embeddings”\n(Angeline et al., 2022). Penelitian ini melakukan pendeteksian pernyataan misogini pada Twitter\ndengan menggunakan Logistic Regression (LR), Convolutional Neural Network (CNN), dan\nLong Short-Term (LSTM), serta TF-IDF, Keras, dan BERT sebagai embedding. Hasil penelitian\nini mendapatkan akurasi terbaik sebesar 86,15% melalui LSTM dengan bantuan BERT.\nTerdapat juga penelitian yang berjudul “Hateminers: Detecting Hate Speech Against Women”\n(Saha et al., 2018). Penelitian tersebut melakukan deteksi (task A) dan klasifikasi (task B)\npernyataan misogini, dimana klasifikasi tersebut dilakukan berdasarkan lima kategori misogini\ndan juga berdasarkan target misogini antara individu atau kelompok. Penelitian dilakukan\ndengan menggunakan Logistic Regression (LR), XGBoost (XGB), dan CatBoost, serta Sentence\nEmbeddings, TF-IDF, dan Bag of Words (BoW) sebagai ekstrasi fitur. Hasil dari penelitian ini\nmenyatakan bahwa akurasi terbaik untuk task A diraih oleh Logistic Regression sebesar 70,4%\ndan task B diraih oleh Catboost dengan nilai rata-rata F-Measure 37%.\nSelanjutnya, terdapat penelitian yang berjudul “Misogynous Text Classification Using SVM\nand LSTM” (Devi & Saharia, 2020). Penelitian ini melakukan klasifikasi pernyataan termasuk\nmisogini atau bukan dalam dataset berbahasa India dan Inggris menggunakan Support Vector\nMachine (SVM) dengan ekstrasi TF-IDF, SVM dengan bantuan N-gram, Long Short-Term\n(LSTM), Bidirectional LSTM (Bi-LSTM), dan LSTM dengan GloVe Embedding. Hasil dari\npenelitian ini memperlihatkan akurasi terbaik untuk dataset berbahasa India diraih oleh SVM\ndengan TF-IDF sebesar 87,1% dan Bi-LSTM sebesar 87%, sedangkan untuk dataset berbahasa\nInggris diraih oleh Bi-LSTM sebesar 93,4% dan LSTM dengan GloVe sebesar 93,3%.\nKemudian, terdapat juga penelitian yang berjudul “Two-Stage Classifier for COVID-19\nMisinformation Detection Using BERT: a Study on Indonesian Tweets” (Faisal & Mahendra,\n2022). Penelitian tersebut melakukan dua tahapan klasifikasi secara pipeline, yaitu tahapan\npertama menyaring tweet yang relevan dan selanjutnya tahapan kedua mendeteksi tweet\nmisinformasi. Penelitian dilakukan menggunakan traditional machine learning (NB, SVM, LR,\nDT, RF, dan XGB) dengan ekstrasi fitur (BoW, TF-IDF, Word2Vec, dan IndoBERT), serta\npenelitian juga dilakukan menggunakan deep learning (BERT, Bi-LSTM, DNN, dan CNN)\ndengan IndoBERT Embedding. Hasil penelitian menyatakan bahwa akurasi terbaik diraih oleh\nBi-LSTM dengan bantuan IndoBERT sebesar 87,02%. Selain itu, terdapat juga penelitian yang\nberjudul “Sexism Identification in Social Networks” (Chaudhary & Kumar, 2023). Penelitian ini\nmelakukan identifikasi pernyataan seksisme dengan dataset berbahasa Inggris dan Spanyol.\nPenelitian ini menggunakan Bi-LSTM yang menghasilkan nilai F1 sebesar 63,56%.\nBerdasarkan latar belakang di atas, maka penulis memutuskan untuk menggunakan\nalgoritma Bidirectional Long Short-Term dengan bantuan IndoBERT Embedding untuk\nmembangun sebuah sistem berbasis web yang dapat melakukan identifikasi terhadap\npernyataan-pernyataan misogini yang tersebar di media sosial. Dengan demikian, penulis\nmemberikan judul penelitian ini berupa “IDENTIFIKASI PERNYATAAN MISOGINI\nBERDASARKAN KOMENTAR MEDIA SOSIAL MENGGUNAKAN BIDIRECTIONAL\nLONG SHORT-TERM DAN INDOBERT EMBEDDING”.\nPenelitian Terdahulu\nNo. Penulis Judul Tahun\nPunyajoy Saha,\nBinny Mathew,\nHateminers: Detecting Hate Speech Against\n1. Pawan Goyal, 2018\nWomen\ndan Animesh\nMukherjee\nMaibam Debina\nMisogynous Text Classification Using SVM\n2. Devi dan 2020\nand LSTM\nNavanath Saharia\nIdentifikasi Pernyataan Misogini Berbahasa\nArnesa Julia Indonesia Berdasarkan Komentar Youtube\n3. 2021\nDamanik Menggunakan GloVe Embedding dan\nRandom Forest Classifier\nRizkyta Shainy\nAngeline, Dade Misogyny Speech Detection Using Long\n4. 2022\nNurjanah, dan Short-Term Memory and BERT Embeddings\nHani Nurrahmi\nDouglas Raevan\nTwo-Stage Classifier for COVID-19\nFaisal dan\n5. Misinformation Detection Using BERT: a 2022\nRahmad\nStudy on Indonesian Tweets\nMahendra\nAtul Chaudhary\n6. Sexism Identification in Social Networks 2023\ndan Ritesh Kumar\nPerbedaan Penelitian\nAdapun perbedaan penelitian ini dengan penelitian yang dilakukan oleh Damanik (2021) adalah\npenelitian tersebut melakukan identifikasi misogini terhadap file .csv berisi komentar yang\ndiunggah ke sistem, sedangkan penelitian ini akan melakukan identifikasi misogini melalui\nkomentar-komentar yang diekstraksi dari link postingan yang diunggah ke dalam sistem. Selain\nitu, perbedaan penelitian ini dengan penelitian yang dilakukan oleh Saha et al. (2018), Devi &\nSaharia (2020), dan Angeline et al. (2022) yang juga membahas identifikasi misogini adalah\npenelitian ini menggunakan kombinasi Bidirectional Long Short-Term sebagai model untuk\nmengidentifikasi dan IndoBERT Embedding sebagai ekstra fitur yang membantu model\nmenganalisis dan mempelajari hubungan kontekstual antar kata dengan lebih baik.\nRumusan Masalah Kebebasan yang diberikan terhadap pengguna media sosial melalui karakteristik anonimitas dan\ndalam mengunggah konten telah menjadi salah satu faktor maraknya unggahan yang berisikan\nhal-hal negatif, termasuk komentar misogini. Dan dalam menyikapi komentar-komentar\ntersebut, perempuan harus meluangkan banyak waktu untuk dapat memblokir atau melaporkan\npengguna yang melakukan pelecehan karena harus memilah mana pernyataan pengguna yang\ntermasuk misogini dan tidak misogini. Hal ini tentunya menyebabkan masyarakat khususnya\nperempuan merasa tidak aman dan nyaman berada di dunia maya maupun dunia nyata. Serta,\ndapat memberikan dampak negatif terhadap psikis perempuan yang menjadi korban. Oleh\nkarena itu, diperlukan suatu pemodelan yang secara otomatis dapat mengidentifikasi suatu\nkomentar mengandung pernyataan misogini atau tidak.\nMetodologi\nData Acquisition\nTahapan ini merupakan tahapan awal yang melakukan pengumpulan data-data komentar\nmedia sosial. Data komentar diambil dari media sosial Youtube, Instagram, dan X\nmenggunakan teknik scrapping. Kemudian, data tersebut dibagi menjadi dua bagian yaitu,\ndata training dan data testing dengan rasio tertentu.\nLabelling\nTahapan ini melakukan proses pemberian label berupa 0 dan 1 untuk setiap data testing.\nDimana, kelas 0 untuk menyatakan pernyataan non-misogini dan kelas 1 untuk pernyataan\nmisogini.\nPreprocessing\nPada tahapan ini, dilakukan serangkaian proses yang bertujuan untuk menghasilkan data\nyang baik sehingga data dapat lebih mudah dimengerti oleh model. Serangkaian proses\ntersebut berupa tahapan cleansing, case folding, punctuation removal, normalization,\nstopword removal, stemming, dan tokenization.\nWord Embedding\nSetelah tahap preprocessing data telah selesai, pada tahapan ini akan dilakukan\npengubahan data menjadi vektor menggunakan word embedding agar dapat melakukan\npemodelan. Word embedding yang digunakan ialah salah satu contoh contextualized word\nembedding yaitu IndoBERT, dimana vektor dari kata yang sama akan dihasilkan berbeda\njika memiliki arti yang berbeda dalam konteks. Representasi vektor yang dilakukan\nmenggunakan IndoBERT ini perlu memberikan inputan sebuah tambahan token [CLS] di\nawal dan [SEP] di akhir.\nModelling\nTahapan ini akan melakukan pelatihan model agar dapat mengidentifikasi data train yang\ntelah diubah menjadi vektor menggunakan algoritma Bidirectional Long Short-Term.\nAlgoritma ini bekerja secara dua arah, dimana lapisan pertama (forward layer) akan\nberfokus untuk urutan setiap kata yang ada pada teks dan lapisan kedua (backward layer)\nakan merepresentasikan konteks dari kata-kata tersebut. Hasil pelatihan model (learned\nmodel) akan digunakan untuk mengidentifikasi komentar.\nOutput\nKeluaran dari keseluruhan proses tersebut adalah identifikasi komentar yang mengandung\nunsur misogini dan non-misogini.\nReferensi Angeline, R. S., Nurjanah, D., & Nurrahmi, H. (2022, August). Misogyny Speech\nDetection Using Long Short-Term Memory and BERT Embeddings. 2022 5th\nInternational Conference on Information and Communications Technology\n(ICOIACT). https://doi.org/https://doi.org/10.1109/ICOIACT55506.2022.9972171\nChaudhary, A., & Kumar, R. (2023). Sexism Identification In Social Networks. In M.\nAliannejadi, G. Faggioli, N. Ferro, & M. Vlachos (Eds.), CLEF 2023: Conference\nand Labs of the Evaluation Forum (pp. 891–900). CEUR-WS.org. https://ceur-\nws.org/Vol-3497/paper-075.pdf\nDamanik, A. J. (2021). IDENTIFIKASI PERNYATAAN MISOGINI BERBAHASA\nINDONESIA BERDASARKAN KOMENTAR YOUTUBE MENGGUNAKAN\nGLOVE EMBEDDING DAN RANDOM FOREST CLASSIFIER. In Universitas\nSumatera Utara.\nDevi, M. D., & Saharia, N. (2020). Misogynous Text Classification Using SVM and\nLSTM. In D. Garg, K. Wong, J. Sarangapani, & S. K. Gupta (Eds.), International\nAdvanced Computing Conference 2020 (pp. 336–348). Springer Singapore.\nhttps://doi.org/https://doi.org/10.1007/978-981-16-0401-0\nFaisal, D. R., & Mahendra, R. (2022). Two-Stage Classifier for COVID-19 Misinformation\nDetection Using BERT: a Study on Indonesian Tweets.\nhttps://arxiv.org/abs/2206.15359\nFuad, B., Amiruddin, M., Yentriyani, A., Kanti, D., Qibtiyah, A., Adkiras, F., Nugroho,\nH. A., Anshor, M. U., Nahe’i, Novianti, Salampessy, O. C., Hutabarat, R. M.,\nRatnawati, R., Mashudi, S., Tardi, S. A., Iswarini, T. S. E., Wiandani, T., & Sitohang,\nV. (2023). CATAHU 2023: Kekerasan terhadap Perempuan di Ranah Publik dan\nNegara: Minimnya Perlindungan dan Pemulihan.\nhttps://komnasperempuan.go.id/catatan-tahunan-detail/catahu2023-kekerasan-\nterhadap-perempuan-di-ranah-publik-dan-negara-minimnya-perlindungan-dan-\npemulihan\nLubis, F. (2021, October 28). Seksisme dan Misogini dalam Perspektif HAM. Komnas\nHAM. https://www.komnasham.go.id/index.php/news/2021/10/28/1963/seksisme-\ndan-misogini-dalam-perspektif-ham.html\nMaharani, A. P. (2022, November 10). Misogini: Kebencian Ekstrim Hanya Karena Kita\nPerempuan. Lembaga Pers Mahasiswa Gelora Sriwijaya.\nhttps://gelorasriwijaya.co/blog/misogini-kebencian-ekstrim-hanya-karena-kita-\nperempuan/ -\nNational Democratic Institute. (2019). Tweets That Chill: Analyzing Online Violence\nAgainst Women in Politics. https://www.ndi.org/tweets-that-chill\nSaha, P., Mathew, B., Goyal, P., & Mukherjee, A. (2018). Hateminers : Detecting Hate\nSpeech Against Women. https://doi.org/https://doi.org/10.48550/arXiv.1812.06700\nMedan, 01 Februari 2024\nMahasiswa yang mengajukan,\n(Stephani Uli Basa Silitonga)\nNIM. 201402068",
  "similar_tokens": [
    "angeline",
    "judul",
    "task",
    "embeddings",
    "bahasa",
    "keras",
    "baik",
    "bidirectional",
    "institute",
    "identifikasi",
    "indonesia",
    "raih",
    "and",
    "democratic",
    "saha",
    "damanik",
    "perempuan",
    "against",
    "teliti",
    "dasar",
    "indobert",
    "using",
    "saharia",
    "vektor",
    "sosial",
    "bantu",
    "media",
    "women",
    "devi",
    "nyata",
    "tahap",
    "glove",
    "hasil",
    "youtube",
    "speech",
    "national",
    "tweets",
    "bilstm",
    "mana",
    "komentar",
    "long",
    "misogini",
    "beda"
  ],
  "filename": "Exum_201402068.pdf",
  "user_id": 17
}