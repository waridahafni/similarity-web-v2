{
  "original_text": "KEMENTERIAN PENDIDKAN, KEBUDAYAAN, RISET, DAN\nTEKNOLOGI\nRSITA UNIVERSITAS SUMATERA UTARA\nFAKULTAS ILMUK OMPUTER DAN TEKNOLOGI INFORMASI\nPROGRAM STUDIS 1 TEKNOLOGI INFORMASI\nTER\nJalan Alumni No. 3 Gedung C, Kampus USUP adang Bulan, Medan 20155\nTelepon/Fax: 061-82 10077| Email: tek.informasi@usu.ac.id | Laman: http://it.usu.ac.id\nFORM PENGAJUAN JUDUL\nNama :Gery Jonathan Manurung\nNIM :211402137\nJudul diajukan oleh* Dosen\nMahasiswa\nBidang IImu (tulis dua bidang) Data Science and Intelligent System\n2. Computer Graphics and Vision\nUji Kelayakan Judul** Diterima Ditolak\nHasil Uji Kelayakan Judul :\nCalon Dosen Pembimbing I: Umaya Ramadhani Putri Nasution S.TI., M.Kom. Paraf CalgA, Dosen Pembimbing I\n(Jika judul dari dosen maka dosen tersebut berhak menjadi pembimbing I)\nCalon Dosen Pembimbing II: Dr. Sawaluddin M.IT\nMedan,Y Februari 2025\nKa. Laboratorium Penelitian,\nCentang salah satu atau keduanya (Fanindia Purnamasari S.TI., M.IT)\n** Pilih salah satu NIP. 198908172019032023\nRINGKASAN JUDUL YANG DIAJUKAN\n*Semua kolom di bawah ini diisi oleh mahasiswa yang sudah mendapat judul\nJudul / Topik Deteksi Deepfake pada Wajah dalam Video dengan Cross-Attention Multi-Scale Vision\nSkripsi Transformer dan EfficientNet\nLatar Belakang Deepfake adalah istilah yang berasal dari gabungan dua kata, yaitu \"deep learning\" dan \"fake\".\ndan Penelitian Teknologi ini mengacu pada video atau konten digital yang telah dimanipulasi secara hiper-\nTerdahulu realistis untuk menampilkan perbuatan seseorang yang sebenarnya tidak pernah terjadi\n(Westerlund, 2019). Deepfake bekerja dengan menggunakan jaringan saraf buatan, khususnya\nGenerative Adversarial Networks (GANs), untuk menganalisis kumpulan besar data seperti\nekspresi wajah, gerak tubuh, suara, hingga infleksi suara seseorang. Teknologi ini\nmenggabungkan kemampuan pemetaan wajah dengan algoritma AI untuk menukar wajah\nseseorang dalam video dengan wajah orang lain.\nKemajuan teknologi deepfake yang semakin mudah diakses dan canggih telah menimbulkan\nancaman besar, khususnya di Indonesia. Deepfake kini digunakan dalam berbagai modus\npenipuan digital, seperti social engineering, account takeover, pencurian identitas, dan pemalsuan\ndokumen. Menurut riset VIDA (2024), \"Where’s The Fraud - Protecting Indonesia Business from\nAI Generated Fraud\", kasus penipuan berbasis deepfake di Indonesia melonjak hingga 1550%\nantara tahun 2022 dan 2023, menunjukkan betapa seriusnya dampak teknologi ini terhadap\nekosistem digital.\nBerbagai pendekatan digunakan untuk mendeteksi deepfake, yang dapat dikategorikan menjadi\nmetode berbasis deep learning, machine learning, dan model statistik. Metode berbasis deep\nlearning mendominasi karena kemampuannya mengekstraksi fitur langsung dari data, dengan\nmodel seperti CNN (XceptionNet, ResNet, EfficientNet) dan RNN (LSTM) menunjukkan akurasi\nrata-rata 89,73% dan AUC sebesar 0,917 pada dataset seperti FaceForensics++ dan Celeb-DF.\nSebaliknya, metode machine learning, seperti SVM dan Random Forest, lebih sederhana tetapi\nkurang efektif dalam menangani dataset kompleks. Model statistik, seperti Kullback-Leibler\ndivergence, meskipun memiliki kegunaan tertentu, jarang digunakan karena keterbatasan dalam\nmenangani manipulasi kompleks. Namun, meski unggul, metode deep learning menghadapi\ntantangan seperti kebutuhan data besar dan penurunan performa pada dataset di luar distribusi\nlatihannya (Rana et al., 2022).\nSalah satu tantangan utama dalam deteksi deepfake adalah ketidakmampuan model untuk\nmelakukan generalisasi dengan baik pada data eksternal, sering kali disebabkan oleh overfitting\nakibat data yang kurang beragam. Das et al. (2021) mengidentifikasi bahwa oversampling dataset\nmenjadi salah satu penyebab utama dan memperkenalkan metode Face-Cutout, yaitu teknik\naugmentasi data yang memotong sebagian kecil area wajah pada data latih. Teknik ini\nmeningkatkan variasi data dan membantu jaringan saraf konvolusional (CNN) menghindari\noverfitting. Dengan metode ini, performa deteksi deepfake meningkat hingga 15,2%–35,3% pada\nberbagai arsitektur CNN, tanpa modifikasi signifikan pada pipeline deteksi. Selain itu, metode ini\nterbukti fleksibel karena tidak bergantung pada jenis dataset tertentu.\nDurasi video yang panjang juga menjadi tantangan, karena dapat menyebabkan komputasi\nberlebihan selama pelatihan model. Bonettini et al. (2021) menemukan bahwa penggunaan 32\nframe per video memberikan keseimbangan antara efisiensi komputasi dan performa model,\nmengurangi risiko overfitting tanpa meningkatkan validation loss secara signifikan dibandingkan\n15 frame. Untuk efisiensi, BlazeFace extractor digunakan untuk mengekstraksi wajah dari setiap\nframe dengan ukuran input 224 × 224 piksel. Namun, penelitian ini tidak memanfaatkan Long\nShort-Term Memory (LSTM) untuk menganalisis hubungan temporal antar frame, sehingga\npotensi mendeteksi inkonsistensi gerakan dan ekspresi wajah belum sepenuhnya dieksplorasi.\nPenelitian yang dilakukan oleh Haq (2021) berfokus pada pengembangan model deteksi video\ndeepfake menggunakan dataset Celeb-DF(V2). Dengan mengekstraksi 2000 frame wajah dari\nvideo asli dan deepfake, peneliti menggunakan model XceptionNet yang dilatih dengan teknik\npemrosesan gambar seperti Gaussian Filter dan Local Binary Pattern (LBP). Hasilnya\nmenunjukkan performa yang signifikan, dengan nilai Area Under Curve (AUC) sebesar 0.87 dan\nakurasi 0.79, mengungguli model ResNet-50 yang juga diuji dalam penelitian ini. Temuan ini\nmenegaskan potensi besar XceptionNet dalam mendeteksi manipulasi wajah pada video deepfake.\nNamun, penelitian ini masih dapat dikembangkan lebih lanjut untuk meningkatkan performa dan\ngeneralisasi model, terutama dalam menghadapi perkembangan teknologi deepfake yang semakin\nkompleks dan canggih.\nSelf-attention mechanism pada Vision Transformer (ViT) telah membawa terobosan besar dalam\ndeteksi deepfake. Mekanisme ini memungkinkan model mempelajari hubungan global antar pixel,\nsehingga dapat menangkap informasi kontekstual tingkat tinggi untuk mendeteksi manipulasi\nvisual secara lebih akurat. Penelitian oleh Khormali dan Yuan (2022) menunjukkan bahwa\nframework DFDT berbasis ViT mencapai akurasi deteksi hingga 99,41% pada FaceForensics++,\n99,31% pada Celeb-DF (V2), dan 81,35% pada WildDeepfake. Kemampuan multi-skala ViT\nmemungkinkan deteksi manipulasi pada berbagai skala dengan efisiensi tinggi. Namun,\npendekatan ini menghadapi tantangan seperti kebutuhan dataset besar untuk menghindari\noverfitting, risiko attention collapse, serta minimnya eksplorasi ViT dibandingkan metode\nberbasis CNN yang lebih mapan.\nKombinasi arsitektur EfficientNet dan Vision Transformer (ViT) telah menunjukkan hasil yang\nsuperior dalam analisis citra. Penelitian oleh Duong et al. (2021) membuktikan bahwa konfigurasi\nViT_Base_Eff_B1_224 mampu mencapai akurasi 97,72% dalam deteksi tuberkulosis dari citra\nX-ray dada. Keunggulan ini didukung oleh efisiensi fitur ekstraksi dari EfficientNet dan\nmekanisme self-attention pada ViT yang memungkinkan pemodelan kompleksitas hubungan\nspasial dalam data citra. Strategi transfer learning menggunakan model pra-latih seperti AdvProp\ndan Noisy Student juga mempercepat proses pembelajaran dan meningkatkan generalisasi model\ntanpa memerlukan dataset yang sangat besar.\nPendekatan CrossViT menawarkan keunggulan tambahan dibandingkan ViT standar. Dengan\narsitektur dual-branch dan mekanisme cross-attention, CrossViT mampu menangkap fitur multi-\nskala secara efektif, memperkaya representasi fitur, dan meningkatkan akurasi klasifikasi hingga\n82,8% pada ImageNet1K (Chen et al., 2021). Selain efisiensi komputasi, CrossViT juga unggul\ndalam fleksibilitas transfer learning. Namun, kompleksitas arsitektur CrossViT dapat menjadi\ntantangan dalam proses pelatihan, terutama dalam skenario dengan dataset besar dan kompleks.\nBerdasarkan penelitian yang telah dilakukan deteksi deepfake menghadapi tantangan seperti\nketerbatasan generalisasi pada data eksternal, kebutuhan dataset besar, risiko overfitting, dan\ntingginya beban komputasi. CNN efektif dalam ekstraksi fitur lokal namun terbatas dalam\nmenangkap hubungan spasial kompleks, sementara ViT unggul dalam pemodelan hubungan\nglobal tetapi rentan terhadap attention collapse dan membutuhkan dataset besar.\nMengatasi kendala tersebut, kombinasi Cross-Attention Multi-Scale Vision Transformer (Cross-\nViT) dan EfficientNet diusulkan. Cross-ViT menangkap artefak manipulasi pada berbagai skala\nspasial dengan mekanisme cross-attention, sementara EfficientNet memberikan efisiensi\nkomputasi melalui scaling parameter yang optimal. Dengan teknik augmentasi seperti Face\nCutout, kombinasi ini menjaga akurasi yang baik dan meningkatkan generalisasi serta efisiensi\nmodel dalam mendeteksi deepfake.\nPenelitian Terdahulu\nNo. Penulis Judul Tahun Keterangan\n1. Sowmen Das, Towards Solving 2021 Penelitian ini mengusulkan\nSelim Seferbekov, the DeepFake metode augmentasi data baru,\nArup Datta, Problem : An Face-Cutout, yang menggunakan\nMd. Saiful Islam, Analysis on informasi landmark wajah untuk\nMd. Ruhul Amin Improving memotong area tertentu pada\nDeepFake gambar, guna mengurangi\nDetection using overfitting dan meningkatkan\nDynamic Face generalisasi model. Hasil\nAugmentation menunjukkan peningkatan\nperforma deteksi DeepFake\ndengan penurunan LogLoss\nsebesar 15.2% hingga 35.3%\ndibandingkan teknik oklusi\nlainnya.\n2. Nicolò Bonettini, Video Face 2021 Penelitian ini menggunakan\nEdoardo Daniele Manipulation pendekatan ensembel CNN yang\nCannas, Detection Through dilengkapi attention mechanicsm\nSara Mandelli, Ensemble of CNNs dan strategi pelatihan siames untuk\nLuca Bondi, mendeteksi manipulasi wajah\nPaolo Bestagini, dalam video. Hasil menunjukkan\nStefano Tubaro performa deteksi yang unggul\ndibandingkan baseline pada\ndataset FF++ dan DFDC, dengan\nefisiensi analisis 4.000 video\ndalam waktu kurang dari 9 jam.\n3. Javid Al Haq Klasifikasi Cepat 2021 Penelitian ini mengembangkan\nModel metode deteksi deepfake dengan\nXceptionnet Dan memanfaatkan Local Binary\nResnet-50 Pada Pattern (LBP) dan model\nVideo Deepfake XceptionNet serta ResNet-50.\nMenggunakan Hasil menunjukkan bahwa\nLocal Binary XceptionNet memiliki performa\nPattern lebih baik dengan AUC 0.87 dan\nakurasi validasi 79%, unggul\ndalam klasifikasi video asli\nmaupun deepfake dibandingkan\nResNet-50.\n4. Aminollah DFDT: An End-to- 2022 Penelitian ini mengembangkan\nKhormali, End DeepFake DFDT, framework deteksi\nJiann-Shiun Yuan Detection deepfake berbasis Vision\nFramework Using Transformer yang memodelkan\nVision hubungan global antar piksel dan\nTransformer memanfaatkan mekanisme re-\nattention. DFDT mencapai akurasi\ntinggi hingga 99.41% pada\nFaceForensics++ dan\nmenunjukkan generalisasi kuat\nantar dataset, membuktikan\nefektivitasnya dalam mendeteksi\nberbagai jenis manipulasi gambar.\n5. Linh T. Duong, Detection of 2021 Penelitian ini memanfaatkan\nNhi H. Le, tuberculosis from kombinasi EfficientNet dan Vision\nToan B. Tran, chest X-ray Transformer (ViT) dengan\nVuong M. Ngo, images: Boosting transfer learning untuk\nPhuong T. Nguyen the performance mendeteksi tuberkulosis dari citra\nwith vision rontgen dada. Model yang\ntransformer and dikembangkan mencapai akurasi\ntransfer learning 97.72% dan nilai AUC tinggi,\nmenunjukkan performa unggul\ndalam membedakan kasus positif\ndan negatif dari model lain serta\npotensi aplikasi luas dalam analisis\ncitra medis.\n6. Chun-Fu Richard, CrossViT: Cross- 2021 Penelitian ini memperkenalkan\nChen, Attention Multi- CrossViT, model Vision\nQuanfu Fan, Scale Vision Transformer yang menggunakan\nRameswar Panda Transformer for dua cabang dengan ukuran patch\nImage berbeda dan cross-attention untuk\nClassification memproses informasi multi-skala.\nCrossViT-18+T2T mencapai\nakurasi top-1 83.0% pada\nImageNet1K.\nRumusan Masalah Teknologi deepfake terus berkembang pesat, menghasilkan manipulasi visual yang semakin\nrealistis dan mudah diakses oleh masyarakat luas. Hal ini menimbulkan berbagai permasalahan,\nterutama dalam penyebaran informasi palsu, penipuan digital, dan ancaman terhadap privasi serta\nkeamanan data. Banyak kasus penyalahgunaan deepfake yang digunakan untuk kepentingan\nkriminal, seperti pencurian identitas, pemalsuan dokumen, hingga manipulasi opini publik. Di sisi\nlain, upaya untuk mendeteksi deepfake masih menghadapi berbagai tantangan, mulai dari akurasi\nyang belum optimal karena overfitting hingga efisiensi sistem yang belum memadai dalam\nmemproses data dalam jumlah besar. Oleh karena itu, diperlukan sistem deteksi deepfake berbasis\nwebsite yang dapat bekerja secara efisien dan juga akurat untuk mengidentifikasi konten\nmanipulatif serta mengurangi dampak negatifnya di berbagai aspek kehidupan.\nMetodologi\nTahapan Penelitian:\n1. Data Acquisition\nData yang digunakan dalam penelitian ini berasal dari dataset Celeb-DF v2 yang\nmemiliki label ground truth untuk video deepfake dan tidak deepfake. Dataset ini dipilih\nkarena kualitas manipulasi yang realistis, menjadikannya tantangan yang sesuai untuk\nevaluasi model deteksi deepfake.\n2. Preprocessing\nTahap preprocessing dilakukan untuk mempersiapkan data mentah agar sesuai dengan\nkebutuhan model. Langkah-langkah preprocessing mencakup:\na. Frame Extraction: Mengambil sebanyak 32 frame representatif dari setiap video\nuntuk mewakili kontennya.\nb. Frame Scaling: Dilakukan penyesuaian ukuran berdasarkan resolusi:\n● 2x Scaling untuk video dengan sisi terlebar kurang dari 300 piksel.\n● Tidak ada rescaling untuk video dengan sisi terlebar antara 300 hingga 1000\npiksel.\n● 0.5x Scaling untuk video dengan sisi terlebar lebih dari 1000 piksel.\n● 0.33x Scaling untuk video dengan sisi terlebar lebih dari 1900 piksel.\nc. Face Cropping: Menggunakan MTCNN (Multi-task Cascaded Convolutional\nNetworks) untuk mendeteksi dan memotong wajah dari setiap frame.\nd. Dimension Normalization: Setiap frame disesuaikan ukurannya agar kompatibel\ndengan dimensi input EfficientNetB1, yaitu 240x240 piksel.\n3. Data Splitting\nDataset dibagi menjadi tiga bagian dengan proporsi 50% untuk training data, 20% untuk\nvalidation, dan 30% untuk testing. Pembagian ini memastikan evaluasi yang seimbang\nuntuk model.\n4. Modeling\nTahapan ini mencakup desain dan integrasi model yang digunakan untuk deteksi\ndeepfake. EfficientNetB1 berfungsi sebagai feature extractor yang menghasilkan dua\ncabang pemrosesan:\na. S-Branch (Small Patch Processing): Menggunakan patch berukuran kecil untuk\nmenangkap informasi lokal seperti artefak kecil pada wajah akibat manipulasi\ndeepfake.\nb. L-Branch (Large Patch Processing): Menggunakan patch berukuran besar untuk\nmenangkap informasi global dari frame yang dapat membantu memahami konteks\nmanipulasi secara keseluruhan.\nSebagai bagian dari augmentasi data, dilakukan teknik face cutout pada training data.\nTeknik ini memotong sebagian wajah secara acak untuk mencegah overfitting dan\nmeningkatkan kemampuan generalisasi model.\nOutput dari kedua cabang (S-Branch dan L-Branch) diintegrasikan menggunakan\nmekanisme cross-attention pada CrossViT (Cross-Attention Vision Transformer).\nMekanisme ini memungkinkan interaksi langsung antara informasi lokal dan global,\nyang meningkatkan kemampuan model dalam mendeteksi manipulasi deepfake. Setiap\ncabang menghasilkan logits terpisah yang kemudian dijumlahkan untuk menghasilkan\nprobabilitas akhir dari klasifikasi. Model ini memprediksi apakah sebuah video adalah\ndeepfake atau tidak deepfake.\n5. Output\nHasil dari proses training adalah website dengan model deteksi deepfake yang mampu\nmenerima input video dan memberikan prediksi apakah video tersebut merupakan\ndeepfake atau bukan. Model ini dapat digunakan dalam aplikasi deteksi deepfake secara\notomatis.\nReferensi Bonettini, N., Bondi, L., Cannas, E. D., Bestagini, P., Mandelli, S., & Tubaro, S. (2020). Video\nface manipulation detection through ensemble of CNNs. Proceedings - International\nConference on Pattern Recognition. https://doi.org/10.1109/ICPR48806.2021.9412711\nChen, C. F., Fan, Q., & Panda, R. (2021). CrossViT: Cross-Attention Multi-Scale Vision\nTransformer for Image Classification. Proceedings of the IEEE International Conference\non Computer Vision. https://doi.org/10.1109/ICCV48922.2021.00041\nDas, S., Seferbekov, S., Datta, A., Islam, M. S., & Amin, M. R. (2021). Towards Solving the\nDeepFake Problem : AAn Analysis on Improving DeepFake Detection using Dynamic\nFace Augmentation. Proceedings of the IEEE International Conference on Computer\nVision, 2021-October. https://doi.org/10.1109/ICCVW54120.2021.00421\nDuong, L. T., Le, N. H., Tran, T. B., Ngo, V. M., & Nguyen, P. T. (2021). Detection of\ntuberculosis from chest X-ray images: Boosting the performance with vision transformer\nand transfer learning. Expert Systems with Applications, 184.\nhttps://doi.org/10.1016/j.eswa.2021.115519\nHaq, J. Al. (2021). Klasifikasi cepat model xceptionnet dan ResNet-50 pada video deepfake\nmenggunakan local binary pattern. In Repository.Uinjkt.Ac.Id.\nhttps://repository.uinjkt.ac.id/dspace/handle/123456789/58537\nKhormali, A., & Yuan, J. S. (2022). DFDT: An End-to-End DeepFake Detection Framework\nUsing Vision Transformer. Applied Sciences (Switzerland), 12(6).\nhttps://doi.org/10.3390/app12062953\nRana, M. S., Nobi, M. N., Murali, B., & Sung, A. H. (2022). Deepfake Detection: A Systematic\nLiterature Review. In IEEE Access (Vol. 10).\nhttps://doi.org/10.1109/ACCESS.2022.3154404\nVIDA. (2024). Penipuan deepfake Indonesia melonjak 1550%, begini cara VIDA\nmemeranginya. VIDA.\nhttps://vida.id/id/pressrelease/penipuan-deepfake-indonesia-melonjak-1550-begini-cara-\nvida-memeranginya\nWesterlund, M. (2019). The emergence of deepfake technology: A review. In Technology\nInnovation Management Review (Vol. 9, Issue 11).\nhttps://doi.org/10.22215/TIMREVIEW/1282\nMedan, 4 Februari 2025\nMahasiswa yang mengajukan,\n(Gery Jonathan Manurung)\nNIM. 211402137",
  "similar_tokens": [
    "frame",
    "kuat",
    "fanindia",
    "pemrosesan",
    "potong",
    "kategori",
    "agam",
    "sepenuh",
    "dukung",
    "efisiensi",
    "kenal",
    "kualitas",
    "aan",
    "d",
    "dr",
    "pisah",
    "fungsi",
    "terang",
    "sebab",
    "teliti",
    "filter",
    "utara",
    "h",
    "ajar",
    "wajah",
    "asal",
    "jenis",
    "informasi",
    "isi",
    "eksplorasi",
    "butuh",
    "luas",
    "otomatis",
    "medan",
    "for",
    "tantang",
    "batas",
    "long",
    "kumpul",
    "mudah",
    "acu",
    "teknik",
    "latih",
    "ka",
    "et",
    "jalan",
    "efisien",
    "layak",
    "lokal",
    "c",
    "usul",
    "acquisition",
    "networks",
    "purnamasari",
    "potensi",
    "tampil",
    "parameter",
    "area",
    "international",
    "analis",
    "s",
    "applied",
    "v",
    "hidup",
    "piksel",
    "laman",
    "identitas",
    "penting",
    "masalah",
    "probabilitas",
    "kurang",
    "desain",
    "uji",
    "ratarata",
    "kampus",
    "paham",
    "improving",
    "citra",
    "truth",
    "tahap",
    "menteri",
    "asli",
    "bimbing",
    "hindar",
    "a",
    "deteksi",
    "temu",
    "label",
    "tangan",
    "ekspresi",
    "binary",
    "aju",
    "judul",
    "engineering",
    "beban",
    "turun",
    "applications",
    "lengkap",
    "global",
    "from",
    "b",
    "through",
    "capai",
    "f",
    "science",
    "resolusi",
    "skripsi",
    "t",
    "meta",
    "beda",
    "bas",
    "bagi",
    "management",
    "on",
    "ambil",
    "langsung",
    "ieee",
    "ground",
    "sawaluddin",
    "mampu",
    "referensi",
    "review",
    "utama",
    "sumatera",
    "prediksi",
    "nilai",
    "face",
    "serius",
    "an",
    "salah",
    "with",
    "mit",
    "augmentation",
    "terima",
    "fokus",
    "tinggi",
    "ekstraksi",
    "i",
    "mkom",
    "optimal",
    "orang",
    "jadi",
    "cegah",
    "interaksi",
    "hasil",
    "masyarakat",
    "bidang",
    "nasution",
    "images",
    "gedung",
    "kaya",
    "no",
    "dimensi",
    "and",
    "signifikan",
    "pralatih",
    "indonesia",
    "technology",
    "guna",
    "efektif",
    "hubung",
    "fakultas",
    "temporal",
    "ringkas",
    "akses",
    "tangkap",
    "mekanisme",
    "jaga",
    "maju",
    "conference",
    "generalisasi",
    "bantu",
    "negatif",
    "chen",
    "le",
    "ramadhani",
    "dosen",
    "gantung",
    "integrasi",
    "rumus",
    "r",
    "konfigurasi",
    "skala",
    "statistik",
    "putri",
    "jarang",
    "akibat",
    "proceedings",
    "ukur",
    "distribusi",
    "e",
    "augmentasi",
    "akurat",
    "centang",
    "milik",
    "kali",
    "latar",
    "kombinasi",
    "kendala",
    "program",
    "kembang",
    "acak",
    "dasar",
    "video",
    "timbul",
    "the",
    "in",
    "nip",
    "representasi",
    "budaya",
    "sara",
    "unggul",
    "gerak",
    "pixel",
    "gabung",
    "memory",
    "nama",
    "sti",
    "kompleksitas",
    "saraf",
    "j",
    "efektivitas",
    "visual",
    "cabang",
    "al",
    "cakup",
    "atas",
    "dokumen",
    "lbp",
    "canggih",
    "universitas",
    "pada",
    "p",
    "amin",
    "topik",
    "performa",
    "standar",
    "mahasiswa",
    "aplikasi",
    "q",
    "modifikasi",
    "bukti",
    "gambar",
    "computer",
    "m",
    "skenario",
    "umaya",
    "end",
    "ter",
    "buat",
    "sesuai",
    "spasial",
    "arsitektur",
    "scale",
    "tulis",
    "nim",
    "n",
    "medis",
    "sisi",
    "l",
    "hadap",
    "manfaat",
    "ii",
    "dampak",
    "riset",
    "vision",
    "sederhana",
    "pilih",
    "banding",
    "tambah",
    "sebar",
    "proses",
    "aman",
    "aspek",
    "tubuh",
    "website",
    "cepat",
    "identifikasi",
    "upaya",
    "using",
    "x",
    "variasi",
    "dekat",
    "metodologi",
    "positif",
    "proporsi",
    "transfer",
    "istilah",
    "komputasi",
    "konvolusional",
    "tingkat",
    "wakil",
    "top",
    "pesat",
    "imbang",
    "kompleks"
  ],
  "filename": "1752189558_Exum_211402137.pdf",
  "user_id": 17
}