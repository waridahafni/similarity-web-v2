{
  "original_text": " \n \n   \n \n \n \nRINGKASAN JUDUL YANG DIAJUKAN  \n \n*Semua kolom di bawah ini diisi oleh mahasiswa yang sudah mendapat judul  \nJudul / Topik \nSkripsi  IDENTIFIKASI PERNYATAAN MISOGINI BERDASARKAN KOMENTAR MEDIA SOSIAL \nMENGGUNAKAN BIDIRECTIONAL LONG SHORT -TERM DAN INDO BERT EMBEDDING  \nLatar Belakang , \nPenelitian \nTerdahulu , dan \nPerbedaan \nPenelitian  Latar Belakang  \nDi Indonesia, masih sering ditemukan masyarakat yang menganut paham patriarki. Hal ini \nmembuat misogini masih terus berkembang secara luas seiring dengan perkembangan ideologi \ntersebut. Misogini sendiri memiliki arti kebencian terhadap perempuan dan pemaha man ini telah \nmelahirkan seorang misoginis. Seorang misoginis memiliki sikap yang memandang bahwa \nperempuan merupakan pihak yang layak untuk disudutkan, ditindas, dan dieksploitasi, serta \nmendapat kebencian. Selain hal ini, terdapat juga kebiasaan yang mer emehkan dan \nmenomorduakan perempuan, menghina dan mendiskriminasikan perempuan, serta menganggap \nbahwa perempuan layak dilecehkan dan diberi kekerasan (Lubis, 2021) (Maharani, 2022) . \nAdapun contoh pernyataan misogini  dapat dilihat pada gambar di bawah ini . \n \nTentunya, perilaku ini sudah termasuk kedalam tindakan kekerasan terhadap perempuan dan \ntelah melanggar prinsip HAM terkait kesetaraan dan nondiskriminasi. Meskipun demikian, \nperilaku ini masih tersebar luas dan bahkan dapat ditemukan di media sosial.  \n      Penggunaan media sosial yang identik dilakukan secara anonim mengakibatkan sering kali \nditemukan pernyataan atau unggahan yang tidak berkenan terhadap sesama masyarakat terutama \nterhadap perempuan. Hal tersebut diperkuat pernyataannya berdasarkan lap oran oleh National \nDemocratic Institute  (National Democratic Institute, 2019),  dimana dikatakan bahwa \nperempuan -perempuan di Kolombia, Kenya, dan Indonesia menjadi yang paling umum \nmengalami kekerasan secara online  berupa bahasa yang menghina . Dan dalam Catatan Tahunan \n(CATAHU) 2023 (Fuad et al., 2023) , Komisi Nasional Anti Kekerasan terhadap Perempuan \n(Komnas Perempuan) mendapatkan pengaduan kasus Kekerasan Siber Berbasis Gender (KSBG) \nsebanyak 1697 kasus yang dimana 869 kasus diantaranya terjadi di ranah publik. Di antara \nkasus -kasus tersebut, sebanya k 383 pelaku merupakan teman media sosial korban dan 304 \npelaku merupakan orang yang tidak dikenal oleh korban. Selain Komnas Perempuan, terdapat \n \n   \n \n \njuga catatan pengaduan dari Lembaga Layanan yang menyatakan sebanyak 148 kasus KSBG \ndiantara semua kasus yang diadukan. Banyaknya kasus yang terjadi ini dapat dan telah \nmenimbulkan rasa tidak aman terhadap perempuan dalam menggunakan teknologi seperti \nhalnya media sosial. Bahkan, beberapa perempuan diantaranya menghentikan sementara \naktivitas mereka di media sosial dan terdapat juga yang berhenti secara permanen menggunakan \nmedia sosial (National Democratic Institute, 2019) . \n      Hal terkait kekerasan melalui jejaring sosial ini tentunya perlu diamati dan dicermati lebih \nlanjut karena telah merugikan perempuan, terutama terkait misogini yang menjadi salah satu \nbentuknya. Akan tetapi, untuk membuktikan suatu pernyataan merupak an misogini atau bukan, \ndiperlukan ketelitian dan pemahaman terhadap setiap konteks kalimat yang ada pada komentar. \nHal tersebut tentunya akan menghabiskan waktu yang cukup lama untuk membuktikan \npernyataannya satu per satu. Sehingga diperlukan suatu pende katan yang dapat mempermudah \nproses tersebut.  \n      Pendekatan yang dapat dilakukan ialah dengan melakukan identifikasi pernyataan misogini \nmenggunakan metode pembelajaran mesin. Sebelumnya telah dilakukan beberapa penelitian \nyang serupa, diantaranya penelitian yang berjudul “ Identifikasi Pernyataan Misogini Berbahasa \nIndonesia Berdasarkan Komentar Youtube Menggunakan GloVe Embedding dan Random \nForest Classifier ” (Damanik, 2021) . Penelitian tersebut berupa skripsi yang melakukan \nidentifikasi pernyataan misogini yang diinput dalam bentuk dokumen menggunakan algoritma \nRandom Forest (RF) dan GloVe Embedding  dengan hasil akurasi 92,5%. Penelitian lainnya \nberjudul “ Misogyny Speech Detection Using Long Short -Term Memory and BERT Embeddings ” \n(Angeline et al., 2022) . Penelitian ini melakukan pendeteksian pernyataan misogini pada Twitter \ndengan menggunakan Logistic Regression (LR) , Convolutional Neural Network (CNN) , dan \nLong Short -Term (LSTM) , serta TF -IDF, Keras, dan BERT sebagai embedding . Hasil penelitian \nini mendapatkan akurasi terbaik sebesar 86,15% melalui LSTM dengan bantuan BERT. \nTerdapat juga penelitian yang berjudul “ Hateminers: Detecting Hate Speech Against Women ” \n(Saha et al., 2018) . Penelitian tersebut melakukan deteksi ( task A ) dan klasifikasi ( task B ) \npernyataan misogini, dimana klasifikasi tersebut dilakukan berdasarkan lima kategori misogini \ndan juga berdasarkan target misogini antara individu atau kelompok. Penelitian dilakukan \ndengan menggunakan  Logistic Regression (LR) , XGBoost (XGB) , dan CatBoost , serta Sentence \nEmbeddings , TF-IDF, dan Bag of Words (BoW)  sebagai ekstrasi fitur. Hasil dari penelitian ini \nmenyatakan bahwa akurasi terbaik untuk task A diraih oleh Logistic Regres sion sebesar 70,4% \ndan task B diraih oleh Catboost dengan nilai rata -rata F -Measure 37%.   \n   \n \n \n      Selanjutnya, terdapat penelitian yang berjudul “ Misogynous Text Classification Using SVM \nand LSTM ” (Devi & Saharia, 2020) . Penelitian ini melakukan klasifikasi pernyataan termasuk \nmisogini atau bukan dalam dataset berbahasa India dan Inggris menggunakan Support Vector \nMachine (SVM ) dengan ekstrasi TF -IDF, SVM dengan bantuan N -gram, Long Short -Term \n(LSTM ), Bidirectional LSTM (Bi -LSTM) , dan LSTM dengan GloVe Embedding . Hasil dari \npenelitian ini memperlihatkan akurasi terbaik untuk dataset berbahasa India diraih oleh SVM \ndengan TF -IDF sebesar 87,1% dan Bi -LSTM sebesar 87%, sedangkan untuk dataset berbahasa \nInggris diraih oleh Bi -LSTM sebesar 93,4% dan LSTM dengan GloVe sebesar 93,3%. \nKemudian, terdapat juga penelitian yang berjudul “ Two-Stage Classifier for COVID -19 \nMisinformation Detection Using BERT: a Study on Indonesian Tweets ” (Faisal & Mahendra, \n2022) . Penelitian tersebut melakukan dua tahapan klasifikasi secara pipeline , yaitu tahapan \npertama menyaring tweet  yang relevan dan selanjutnya tahapan kedua mendeteksi tweet  \nmisinformasi. Penelitian dilakukan menggunakan traditional machine learning  (NB, SVM, LR, \nDT, RF, dan XGB) dengan ekstrasi fitur (BoW, TF -IDF, Word2Vec, dan IndoBERT), serta \npenelitian juga dilakukan menggunakan deep learning  (BERT, Bi -LSTM, DNN, dan CNN) \ndengan IndoBERT Embedding . Hasil penelitian menyatakan bahwa akurasi terbaik diraih oleh \nBi-LSTM dengan bantuan IndoBERT sebesar 87,02%. Selain itu, terdapat juga penelitian yang \nberjudul “ Sexism Identification in Social Networks”  (Chaudhary & Kumar, 2023) . Penelitian ini \nmelakukan identifikasi pernyataan seksisme dengan dataset berbahasa Inggris dan Spanyol. \nPenelitian ini menggunakan Bi -LSTM yang menghasilkan nilai F1 sebesar 63,56%.  \n      Berdasarkan latar belakang di atas, maka penulis memutuskan untuk menggunakan \nalgoritma Bidirectional Long Short -Term  dengan bantuan IndoBERT Embedding untuk \nmembangun sebuah sistem berbasis web yang dapat melakukan identifikasi terhadap \npernyataan -pernyataan misogini yang tersebar di media sosial. Dengan demikian, penulis \nmemberikan judul penelitian ini berupa “IDENTIFI KASI PERNYATAAN MISOGINI \nBERDASARKAN KOMENTAR MEDIA SOSIAL MENGGUNAKAN BIDIRECTIONAL \nLONG SHORT -TERM DAN INDOBERT EMBEDDING”.  \n \nPenelitian Terdahulu  \nNo. Penulis  Judul  Tahun  \n1. Punyajoy  Saha, \nBinny Mathew, \nPawan Goyal, \ndan Animesh \nMukherjee  Hateminers: Detecting Hate Speech Against \nWomen  2018   \n   \n \n \n2. Maibam Debina \nDevi dan \nNavanath Saharia  Misogynous Text Classification Using SVM \nand LSTM  2020  \n3. Arnesa Julia \nDamanik  Identifikasi Pernyataan Misogini Berbahasa \nIndonesia Berdasarkan Komentar Youtube \nMenggunakan GloVe Embedding  dan \nRandom Forest Classifier  2021 \n4. Rizkyta Shainy \nAngeline, Dade \nNurjanah, dan \nHani Nurrahmi  Misogyny Speech Detection Using Long \nShort -Term Memory and BERT Embeddings  2022  \n5. Douglas Raevan \nFaisal dan \nRahmad \nMahendra  Two-Stage Classifier for COVID -19 \nMisinformation Detection Using BERT: a \nStudy on Indonesian Tweets  2022 \n6. Atul Chaudhary \ndan Ritesh K umar Sexism Identification in Social Networks  2023  \n \nPerbedaan Penelitian  \nAdapun perbedaan penelitian ini dengan penelitian yang dilakukan oleh Damanik (2021)  adalah \npenelitian tersebut melakukan identifikasi misogini terhadap file .csv  berisi komentar yang \ndiunggah ke sistem, sedangkan penelitian ini akan melakukan identifikasi misogini melalui \nkomentar -komentar yang diekstraksi dari link postingan yang diunggah ke dalam sistem. Selain \nitu, perbedaan penelitian ini dengan penelitian yang dilakukan oleh Saha et al. (2018) , Devi & \nSaharia (2020) , dan Angeline et al. (2022)  yang juga membahas identifikasi misogini adalah \npenelitian ini menggunakan kombinasi Bidirectional Long Short -Term sebagai model untuk \nmengidentifikasi dan IndoBERT Embedding  sebagai ekstra fitur yang membantu model \nmenganalisis dan mempelajari hubungan kontekstual antar kata dengan lebih baik . \nRumusan Masalah  Kebebasan yang diberikan terhadap pengguna media sosial melalui karakteristik anonimitas dan \ndalam mengunggah konten telah menjadi salah satu faktor maraknya unggahan yang berisikan \nhal-hal negatif, termasuk komentar misogini. Dan dalam menyikapi komentar -komentar \ntersebut, perempuan harus meluangkan banyak waktu untuk dapat memblokir atau melaporkan \npengguna yang melakukan pelecehan karena harus memilah mana pernyataan pengguna yang \ntermasuk misogini dan tidak misogini. Hal ini tentunya menyebabkan masyarakat khususnya \nperempuan merasa tidak aman dan nyaman berada di dunia maya maupun dunia nyata. Serta , \ndapat memberikan dampak negatif terhadap psikis perempuan yang menjadi korban. Oleh \nkarena itu, diperlukan suatu pemodelan yang secara otomatis dapat mengidentifikasi suatu \nkomentar mengandung pernyataan misogini atau tidak.   \n   \n \n \n \nMetodologi   \n \nData Acquisition  \nTahapan ini merupakan tahapan awal yang melakukan pengumpulan data -data komentar \nmedia sosial. Data komentar diambil dari media sosial Youtube, Instagram, dan X \nmenggunakan teknik scrapping . Kemudian, data tersebut dibagi menjadi dua bagian yaitu, \ndata training  dan data testing  dengan rasio tertentu.  \n \nLabelling  \nTahapan ini melakukan proses pemberian label berupa 0 dan 1 untuk setiap data testing . \nDimana, kelas 0 untuk menyatakan pernyataan non -misogini dan kelas 1 untuk pernyataan \nmisogini.  \n \nPreprocessing  \nPada tahapan ini, dilakukan serangkaian proses yang bertujuan untuk menghasilkan data \nyang baik sehingga data dapat lebih mudah dimengerti oleh model. Serangkaian proses \ntersebut berupa tahapan cleansing , case folding , punctuation  removal , normalization , \nstopword removal , stemming , dan tokenization . \n \n \n   \n \n \nWord Embedding  \nSetelah tahap preprocessing data  telah selesai, pada tahapan ini akan dilakukan \npengubahan data menjadi vektor menggunakan word embedding  agar dapat melakukan \npemodelan. Word embedding yang digunakan ialah salah satu contoh contextualized word \nembedding  yaitu IndoBERT, dimana vektor dari kata yang sama akan dihasilkan berbeda \njika memiliki arti yang berbeda dalam konteks. Representasi vektor yang dilakukan \nmenggunakan IndoBERT ini perlu memberikan inputan sebuah tambahan token [CLS] di \nawal dan [SEP] di akhir. \n \nModelling  \nTahapan ini akan melakukan pelatihan model agar dapat mengidentifikasi data train  yang \ntelah diubah menjadi vektor menggunakan algoritma Bidirectional Long Short -Term . \nAlgoritma ini bekerja secara dua arah, dimana lapisan pertama ( forward layer ) akan \nberfokus  untuk urutan setiap kata yang ada pada teks dan lapisan kedua ( backward layer ) \nakan merepresentasikan konteks dari kata -kata tersebut. Hasil pelatihan model ( learned \nmodel ) akan digunakan untuk mengidentifikasi komentar . \n \nOutput  \nKeluaran dari keseluruhan proses tersebut adalah identifikasi komentar yang mengandung \nunsur misogini dan non -misogini.  \nReferensi  Angeline, R. S., Nurjanah, D., & Nurrahmi, H. (2022, August). Misogyny Speech \nDetection Using Long Short -Term Memory and BERT Embeddings. 2022 5th \nInternational Conference on Information and Communications Technology \n(ICOIACT) . https://doi.org/https://doi.org/10.1109/ICOIACT55506.2022.9972171  \nChaudhary, A., & Kumar, R. (2023). Sexism Identification In Social Networks. In M. \nAliannejadi, G. Faggioli, N. Ferro, & M. Vlachos (Eds.), CLEF 2023: Conference \nand Labs of the Evaluation Forum  (pp. 891 –900). CEUR -WS.org. https://ceur -\nws.org/Vol -3497/paper -075.pdf  \nDamanik, A. J. (2021). IDENTIFIKASI PERNYATAAN MISOGINI BERBAHASA \nINDONESIA BERDASARKAN KOMENTAR YOUTUBE MENGGUNAKAN \nGLOVE EMBEDDING DAN RANDOM FOREST CLASSIFIER. In Universitas \nSumatera Utara . \nDevi, M. D., & Saharia, N. (2020). Misogynous Text Classification Using SVM and \nLSTM. In D. Garg, K. Wong, J. Sarangapani, & S. K. Gupta (Eds.), International \nAdvanced Computing Conference 2020  (pp. 336 –348). Springer Singapore. \nhttps://doi.org/https://doi.org/10.1007/978 -981-16-0401 -0 \nFaisal, D. R., & Mahendra, R. (2022). Two-Stage Classifier for COVID -19 Misinformation \nDetection Using BERT: a Study on Indonesian Tweets . \nhttps://arxiv.org/abs/2206.15359  \nFuad, B., Amiruddin, M., Yentriyani, A., Kanti, D., Qibtiyah, A., Adkiras, F., Nugroho, \nH. A., Anshor, M. U., Nahe’i, Novianti, Salampessy, O. C., Hutabarat, R. M., \nRatnawati, R., Mashudi, S., Tardi, S. A., Iswarini, T. S. E., Wiandani, T., & Sitohang,  \n   \n \n \nV. (2023). CATAHU 2023: Kekerasan terhadap Perempuan di Ranah Publik dan \nNegara: Minimnya Perlindungan dan Pemulihan . \nhttps://komnasperempuan.go.id/catatan -tahunan -detail/catahu2023 -kekerasan -\nterhadap -perempuan -di-ranah -publik -dan-negara -minimnya -perlindungan -dan-\npemulihan  \nLubis, F. (2021, October 28). Seksisme dan Misogini dalam Perspektif HAM . Komnas \nHAM. https://www.komnasham.go.id/index.php/news/2021/10/28/1963/seksisme -\ndan-misogini -dalam -perspektif -ham.html  \nMaharani, A. P. (2022, November 10). Misogini: Kebencian Ekstrim Hanya Karena Kita \nPerempuan . Lembaga Pers Mahasiswa Gelora Sriwijaya. \nhttps://gelorasriwijaya.co/blog/misogini -kebencian -ekstrim -hanya -karena -kita-\nperempuan/ - \nNational Democratic Institute. (2019). Tweets That Chill: Analyzing Online Violence \nAgainst Women in Politics . https://www.ndi.org/tweets -that-chill \nSaha, P., Mathew, B., Goyal, P., & Mukherjee, A. (2018). Hateminers : Detecting Hate \nSpeech Against Women . https://doi.org/https://doi.org/10.48550/arXiv.1812.06700  \n \n \nMedan, 01 Februari 2024  \nMahasiswa yang mengajukan,  \n \n(Stephani Uli Basa Silitonga ) \n          NIM.  201402068  \n",
  "similar_tokens": [
    "t",
    "u",
    "j",
    "u",
    " ",
    "k",
    "a",
    "t",
    "e",
    "g",
    "o",
    "r",
    "i",
    " ",
    "a",
    "n",
    "d",
    " ",
    "k",
    "o",
    "n",
    "t",
    "e",
    "n",
    " ",
    "i",
    "n",
    "d",
    "o",
    "n",
    "e",
    "s",
    "i",
    "a",
    " ",
    "s",
    "a",
    "l",
    "a",
    "h",
    " ",
    "k",
    "o",
    "m",
    "e",
    "n",
    "t",
    "a",
    "r",
    " ",
    "d",
    "a",
    "s",
    "a",
    "r",
    " ",
    "o",
    "n",
    "l",
    "i",
    "n",
    "e",
    " ",
    "t",
    "w",
    "i",
    "t",
    "t",
    "e",
    "r",
    " ",
    "j",
    "u",
    "d",
    "u",
    "l",
    " ",
    "l",
    "o",
    "n",
    "g",
    " ",
    "t",
    "e",
    "k",
    "s",
    " ",
    "t",
    "e",
    "l",
    "i",
    "t",
    "i",
    " ",
    "s",
    "o",
    "s",
    "i",
    "a",
    "l",
    " ",
    "m",
    "e",
    "m",
    "o",
    "r",
    "y",
    " ",
    "n",
    "e",
    "g",
    "a",
    "t",
    "i",
    "f",
    " ",
    "m",
    "a",
    "h",
    "a",
    "s",
    "i",
    "s",
    "w",
    "a",
    " ",
    "g",
    "u",
    "n",
    "a"
  ],
  "output_path": "uploads\\results\\17\\Exum_211402154_exum_combined.pdf",
  "user_id": 17
}